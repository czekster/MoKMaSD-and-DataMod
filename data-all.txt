ID;Year;Bibtex-entry;Title;Abstract;Author1;Author2;Author3;Author4;Author5;Author6;Keyword1;Keyword2;Keyword3;Keyword4;Keyword5;Keyword6;Keyword7;Keyword8
1;2012;cerone2012modelling;Modelling and Knowledge Management for Sustainable Development;This paper introduces the motivation and aim of the 1st International Symposium on Modelling and Knowledge Management for Sustainable Development (MoKMaSD 2012), inspired by the POST-2015 UN Development Agenda. Then the keynote paper and the four contributed papers presented at the Symposium are summarised and related to the POST-2015 UN Development Agenda.;Antonio Cerone;Alexeis Garcia-Perez;;;;;;;;;;;;
2;2012;kahramanougullari2014algorithmic;Algorithmic Systems Ecology Experiments on Multiple Interaction Types and Patches;Dynamic behavior in ecosystems can emerge as a result of multiple interactions of different types as well as movements of the ecosystem species between different patches. The extinction behaviors in ecosystem models, which can result from the small species numbers, bring stochasticity to the foreground as they are often not observable in deterministic representations. To this end, we demonstrate an integrated approach to ecosystem modeling from an algorithmic systems biology point of view. We use a modeling interface, called LIME, which allows us to give biologically intuitive models of a plant-pollinator system's descriptions with varying interaction types and patches. Our models, written in a narrative style, are automatically translated into stochastic programming languages. The discrete stochastic nature of the models brings about the possibility to analyze the models with respect to their simulations as well as various graph representations. Our analysis provides an assessment of the functional dynamics of ecosystems with respect to the influence of various interaction patterns and patch links.;Ozan Kahramanoğulları;James F. Lynch;Corrado Priami;;;;Ecosystem modeling;Plant-pollinator networks;Multiple interactions;Stochasticity;;;;
3;2012;barbuti2014modelling;Modelling Population Dynamics Using Grid Systems;A new formalism, Grid Systems, aimed at modelling population dynamics is presented. The formalism is inspired by concepts of Membrane Computing (P Systems) and spatiality dynamics of Cellular Automata. The semantics of Grid Systems describes how stochasticity is exploited for reaction duration as well as reaction selection. Grid Systems perform reactions in maximally parallel manner, imitating natural processes. Environmental events that change population behaviour can be defined in Grid Systems as rewrite rules. A population model of a species of mosquitoes, Aedes albopictus, is presented. The model considers three types of external events: temperature change, rainfall, and desiccation. The events change the behaviour of the species directly or indirectly. Each individual in the population can move around in the ecosystem. The simulation of the model was performed by using a semantics based tool.;Roberto Barbuti;Antonio Cerone;Andrea Maggiolo-Schettini;Paolo Milazzo;Suryana Setiawan;;;;;;;;;
4;2012;bernardo2014transition;Transition to Sustainability: Italian Scenarios Towards a Low-Carbon Economy;This paper analyzes different policies that may promote the transition to sustainability, with a particular focus on the energy sector. We present a dynamic simulation model where three different strategies for sustainability are identified: reduction in GHG emissions, improvements in energy efficiency and the development of the renewable energy sector. Our aim is to evaluate the dynamics that those strategies may produce in the economy, looking at different performance indicators: rate of growth, unemployment, fiscal position, GHG emission, and transition to renewable energy sources.;Giovanni Bernardo;Simone D'Alessandro;;;;;Energy transition;System dynamics;Scenario analysis;;;;;
5;2012;bolisani2014models;Models of Knowledge Transfer for Sustainable Development;Sustainable development requires that distant organisations connect to one another and exchange knowledge. Online social networks have the potential to support these processes. It is however important to understand and model the processes of knowledge transfer that can effectively occur on the Internet. This paper explores recent literature with the purpose to highlight relevant formal approaches that can help to model and analyse the processes of inter-organisational knowledge transfer for sustainable development.;Ettore Bolisani;Francesca Scramoncin;Siraj Ahmed Shaikh;;;;;;;;;;;
6;2012;gong2014framework;A Framework for Translating Legal Knowledge into Administrative Processes: Dynamic Adaption of Business Processes;Adapting to and complying with frequently changing legislation quickly against low costs requires organizations to adapt their business processes automatically. Semantic representation of legal knowledge is a prerequisite for the automatic creation of business processes. Business Rules (BR) can be used to capture legal knowledge and business processes can be created by selecting, composing and invoking Semantic Web Services (SWS). In this paper, a modeling framework is presented that enables the automatic creation of business process by invoking SWSs. Process creation is conducted by BRs derived from legislation. The framework addresses the modeling of legal knowledge representation and service descriptions that are required for creating operational processes at runtime. The framework is briefly illustrated by a legislation implementation case study which shows how compliance between business processes and legislation is ensured.;Yiwei Gong;Marijn Janssen;;;;;Business process management;Business rule;Semantic Web Service;Legal knowledge representation;Administrative organization;;;
7;2013;caceres2014towards;Towards Knowledge Modeling for Sustainable Transport;The paradigm shift from the current energy consumption model towards a sustainable model requires to develop new behaviors and strategies. This is particularly relevant in domains like the public transport. Many providers are currently offering services to assist passengers to plan their routes. However, these approaches are often restricted to some specific area or transport medium. We suggest using a Linked Data perspective, which makes simpler to combine data from different sources, as well as extending and managing them. Moreover, it makes possible to enrich the basic model to the extent of developing a knowledge model, able to use semantic techniques to unfold even better strategies. In this paper we present a proposal in the transport domain, which refines a basic model into a Transmodel specification and later adds more information according to the IFOPT model. This defines a knowledge model, which can be used to develop sustainable transport strategies.;Paloma Cáceres;Carlos E. Cuesta;José María Cavero;Belén Vela;Almudena Sierra-Alonso;;Sustainable development;Knowledge management;Semantic web;Transmodel;IFOPT;RDF;;
8;2013;kloos2014xbrl;XBRL-Driven Business Process Improvement: A Simulation Study in the Accounting Domain;The eXtensible Business Reporting Language (XBRL) has been developed to standardize financial reporting. It could also improve internal business processes. Yet there is no scientific research to substantiate this claim. In this paper we use discrete-event simulation to determine the impact of XBRL on internal business processes. Simulation models of the existing and possible new situation are developed in a case study within the accounting domain. The redesigned processes are validated in a workshop. XBRL allows the merging of accounting and fiscal reporting processes resulting in a reduction of the duplication of activities and higher information quality. In particular, it is demonstrated that information quality, efficiency and lead-time can be improved by adoption of XBRL. In addition to technology-standardization on XBRL, data-standardization is a necessary precondition for realizing benefits.;Martin Kloos;Joris Hulstijn;Mamadou Seck;Marijn Janssen;;;XBRL;Standardization;Accounting;Simulation;;;;
9;2013;perez2014role;The Role of Linked Data and Semantic-Technologies for Sustainability Idea Management;Idea Management Systems (IMS) manage the innovation life-cycle from the moment of invention until ideas are implemented in the market. During the life-cycle the IMS supports collaboration, allows idea enrichment with comments, contextual data, or connected to other relevant ideas. Semantic technologies can improve the knowledge management capabilities of IMSs allowing relevant information to be easily linked to ideas. Many Enterprises concerned with sustainability encourage employee's participation as a means to boost creative innovation within their Sustainability Initiatives. However little work has examined the role of an IMS within Sustainability. In this paper we analyse the impact of a semantic-enabled IMS within a sustainability innovation process. In particular, how ideas can be enriched with contextual Linked Open Data (LOD), especially Life-Cycle Assessment (LCA) data, to improve the understanding, implication and value of the idea from the sustainability perspective.;Alain Perez;Felix Larrinaga;Edward Curry;;;;Idea management systems;Semantic web;Linked data;Sustainability;Life-cycle assessment;;;
10;2013;setiawan2014stochastic;Stochastic Modelling of Seasonal Migration Using Rewriting Systems with Spatiality;Seasonal migration is the long-distance movement of a large number of animals belonging to one or more species that occurs on a seasonal basis. It is an important phenomenon that often has a major impact on one or more ecosystem(s). It is not fully understood how this population dynamics phenomenon emerges from the behaviours and interactions of a large number of animals. We propose an approach to the modelling of seasonal migration in which dynamics is stochastically modelled using rewriting systems, and spatiality is approximated by a grid of cells. We apply our approach to the migration of a wildebeest species in the Serengeti National Park, Tanzania. Our model relies on the observations that wildebeest migration is driven by the search for grazing areas and water resources, and animals tend to follow movements of other animals. Moreover, we assume the existence of dynamic guiding paths. These paths could either be representations of the individual or communal memory of wildebeests, or physical tracks marking the land. Movement is modelled by rewritings between adjacent cells, driven by the conditions in the origin and destination cells. As conditions we consider number of animals, grass availability, and dynamic paths. Paths are initialised with the patterns of movements observed in reality, but dynamically change depending on variation of movement caused by other conditions. This methodology has been implemented in a simulator that visualises grass availability as well as population movement.;Suryana Setiawan;Antonio Cerone;;;;;;;;;;;;
11;2013;barbuti2014computational;A Computational Formal Model of the Invasiveness of Eastern Species in European Water Frog Populations;European water frog populations are mainly composed by two species: Pelophylax lessonae (pool frog) and Pelophylax esculentus (edible frog). These populations are called L-E complexes. Edible frogs are a hybrid form between P. lessonae and Pelophylax ridibundus (eastern lake frog) and they reproduce in a particular way, called hybridogenesis. These frog populations have been studied in the contexts of evolution and speciation. In order to have stability of L-E complexes (namely self-maintainance of the population structure) some conditions are necessary. We present a computational formal model of European water frog population based on a variant of P systems in which evolution rules are applied in a probabilistic maximally parallel manner. Probabilities of application of rules will be computed on the basis of parameters to be associated with each rule. By means of our model we show how the stabilization of L-E complexes can be obtained. In particular, we show how the introduction of translocated eastern lake frogs in such complexes can lead to the collapse of the populations. The study of conditions for population stability and of possible threats to endangered species is of particular importance for the maintenance of biodiversity, which is an aspect of sustainable development.;Roberto Barbuti;Pasquale Bove;Andrea Maggiolo-Schettini;Paolo Milazzo;Giovanni Pardini;;;;;;;;;
12;2013;philippou2014process;Process Ordering in a Process Calculus for Spatially-Explicit Ecological Models;In this paper we extend palps, a process calculus proposed for the spatially-explicit individual-based modeling of ecological systems, with the notion of a policy. A policy is an entity for specifying orderings between the different activities within a system. It is defined externally to a palps model as a partial order which prescribes the precedence order between the activities of the individuals of which the model is comprised. The motivation for introducing policies is twofold: one the one hand, policies can help to reduce the state-space of a model, on the other hand, they are useful for exploring the behavior of an ecosystem under different assumptions on the ordering of events within the system. To take account of policies, we refine the semantics of palps via a transition relation which prunes away executions that do not respect the defined policy. Furthermore, we propose a translation of palps into the probabilistic model checker prism. We illustrate our framework by applying prism on palps models with policies for conducting simulation and reachability analysis.;Anna Philippou;Mauricio Toro;;;;;;;;;;;;
13;2013;penna2014dispas;DISPAS: An Agent-Based Tool for the Management of Fishing Effort;We introduce DISPAS, Demersal fIsh Stock Probabilistic Agent-based Simulator, with the aim of helping to investigate and understand sustainability in the exploitation of fishery resources. The simulator has capabilities for exploring different fishing scenarios, focusing on the case study of the common sole (Solea solea) stock in the Northern Adriatic Sea (Mediterranean Sea). In order to assess and predict the availability of the fish stock under different fishing efforts, the simulator allows the user to specify fishing mortality rates (F) on a monthly basis. We present some preliminary results simulating different scenarios.;Pierluigi Penna;Nicola Paoletti;Giuseppe Scarcella;Luca Tesei;Mauro Marini;Emanuela Merelli;Ecosystem science;Simulation of biological systems;Agent-based methodologies;Fish stock assessment;Common sole;Adriatic Sea;;
14;2014;nozza2015latent;A Latent Representation Model for Sentiment Analysis in Heterogeneous Social Networks;The growing availability of social media platforms, in particular microblogs such as Twitter, opened new way to people for expressing their opinions. Sentiment Analysis aims at inferring the polarity of these opinions, but most of the existing approaches are based only on text, disregarding information that comes from the relationships among users and posts. In this paper we consider microblogs as heterogeneous networks and we use an approach based on latent representation of nodes to infer, given a specific topic, the sentiment polarity of posts and users at the same time. The experimental investigation show that our approach, by taking into account both content and relationship information, outperforms supervised classifiers based only on textual content.;Debora Nozza;Daniele Maccagnola;Vincent Guigue;Enza Messina;Patrick Gallinari;;;;;;;;;
15;2014;gabrielli2015use;Use of Mobile Phone Data to Estimate Visitors Mobility Flows;Big Data originating from the digital breadcrumbs of human activities, sensed as by-product of the technologies that we use for our daily activities, allows us to observe the individual and collective behavior of people at an unprecedented detail. Many dimensions of our social life have big data "proxies", such as the mobile calls data for mobility. In this paper we investigate to what extent data coming from mobile operators could be a support in producing reliable and timely estimates of intra-city mobility flows. The idea is to define an estimation method based on calling data to characterize the mobility habits of visitors at the level of a single municipality.;Lorenzo Gabrielli;Barbara Furletti;Fosca Giannotti;Mirco Nanni;Salvatore Rinzivillo;;Big data;Urban population;Inter-city mobility;Datamining;;;;
16;2014;mukala2015abstract;An Abstract State Machine (ASM) Representation of Learning Process in FLOSS Communities;Free/Libre Open Source Software (FLOSS) communities as collaborative environments enable the occurrence of learning between participants in these groups. With the increasing interest research on understanding the mechanisms and processes through which learning occurs in FLOSS, there is an imperative to describe these processes. One successful way of doing this is through specification methods. In this paper, we describe the adoption of Abstract States Machines (ASMs) as a specification methodology for the description of learning processes in FLOSS. The goal of this endeavor is to represent the many possible steps and/or activities FLOSS participants go through during interactions that can be categorized as learning processes. Through ASMs, we express learning phases as states while activities that take place before moving from one state to another are expressed as transitions.;Patrick Mukala;Antonio Cerone;Franco Turini;;;;Process modeling;Abstract State Machines (ASMs);FLOSS communities;Learning processes;;;;
17;2014;sameen2015mathematical;A Mathematical Model for Assessing KRAS Mutation Effect on Monoclonal Antibody Treatment of Colorectal Cancer;The most challenging task in colorectal cancer research nowadays is to understand the development of acquired resistance to anti-EGFR drugs. The key reason for this problem is the KRAS mutations produced after the treatment with monoclonal antibodies (mAb). KRAS screening tests done before the start of the treatment are not very sensitive to identify minute quantity of the mutated cells, which can produce resistance to the therapy after the beginning of the treatment. Here we present a mathematical model for the analysis of KRAS mutations behavior in colorectal cancer with respect to mAb treatments. To evaluate the drug performance we have developed equations for two types of tumors cells, i.e. KRAS mutated and KRAS wildtype. Both tumor cell populations were treated with a combination of mAb and chemotherapy drugs. It was observed that even the minimal initial concentration of KRAS mutation before the treatment has the ability to make the tumor refractory to the treatment. Patient's immune responses are specifically taken into considerations and it is found that, in case of KRAS mutations, the immune strength does not affect medication efficacy. Finally, Cetuximab (mAb) and Irinotecan (chemotherapy) drugs are analyzed as firstline treatment of colorectal cancer with few KRAS mutated cells. Results show that this combined treatment is only effective for patients with high immune strengths and it should not be recommended as first-line therapy for patients with moderate immune strengths or weak immune systems because of a potential risk of relapse, with KRAS mutant cells acquired resistance involved with them.;Sheema Sameen;Roberto Barbuti;Paolo Milazzo;Antonio Cerone;;;Colorectal cancer;Mathematical model;Monoclonal antibody;resistance;KRAS mutation;;;
18;2014;nieto2015sea;Sea-Scale Agent-Based Simulator of Solea solea in the Adriatic Sea;DISPAS is an agent-based simulator for fish stock assessment developed as a decision making support for the sustainable management of fishery. In this work we enlarge the underlying model of DISPAS allowing it to model and simulate a multi-scale scenario. We retain the currently available spatial scale, able to represent a limited average region of the sea, and we introduce a new spatial macro-scale, able to represent the whole sea. At the macro-scale a single agent represents an area of five square nautical miles and manages groups of fish in different age classes. The interactions among the macro agents permit the exchange of individuals of each class among neighbor areas. A case study regarding the Solea solea (Linnaeus, 1758, Soleidae) stock of the northern Adriatic Sea is used to show the intended approach, taking into account the available data, coming from fishery independent scientific surveys.;Cesar Augusto Nieto Coria;Luca Tesei;Giuseppe Scarcella;Tommaso Russo;Emanuela Merelli;;Modeling and simulation;Agent-based modeling;Ecosystem modeling;Common sole;Adriatic Sea;Multi-scale modeling;;
19;2014;cerone2015research;Research Challenges in Modelling Ecosystems;Ecosystems and their biodiversity have to be protected and preserved as sources of services and goods. The human population controls and modifies ecosystems to improve its health conditions and welfare. The consequences of human activities should be carefully monitored and ecosystems should be managed to protect all of the species and preserve their functioning. The development of strategies for ecosystem management benefits from the use of computational techniques to model the dynamics of species that interact with their abiotic and biotic environment. Life scientists and computer scientists need to work together to define and analyse ecosystem models. However, there is a multifaceted gap between the approaches used in life science and those used in computer science. Such gap is both cultural and technical, and results in a number of challenges. In this paper we identify these challenges and provide technical and cultural proposals for solving them.;Antonio Cerone;Marco Scotti;;;;;;;;;;;;
20;2014;guidotti2015retrieving;Retrieving Points of Interest from Human Systematic Movements;Human mobility analysis is emerging as a more and more fundamental task to deeply understand human behavior. In the last decade these kind of studies have become feasible thanks to the massive increase in availability of mobility data. A crucial point, for many mobility applications and analysis, is to extract interesting locations for people. In this paper, we propose a novel methodology to retrieve efficiently significant places of interest from movement data. Using car drivers' systematic movements we mine everyday interesting locations, that is, places around which people life gravitates. The outcomes show the empirical evidence that these places capture nearly the whole mobility even though generated only from systematic movements abstractions.;Riccardo Guidotti;Anna Monreale;Salvatore Rinzivillo;Dino Pedreschi;Fosca Giannotti;;;;;;;;;
21;2015;grossi2015clustering;Clustering Formulation Using Constraint Optimization;The problem of clustering a set of data is a textbook machine learning problem, but at the same time, at heart, a typical optimization problem. Given an objective function, such as minimizing the intracluster distances or maximizing the inter-cluster distances, the task is to find an assignment of data points to clusters that achieves this objective. In this paper, we present a constraint programming model for a centroid based clustering and one for a density based clustering. In particular, as a key contribution, we show how the expressivity introduced by the formulation of the problem by constraint programming makes the standard problem easy to be extended with other constraints that permit to generate interesting variants of the problem. We show this important aspect in two different ways: first, we show how the formulation of the density-based clustering by constraint programming makes it very similar to the label propagation problem and then, we propose a variant of the standard label propagation approach.;Valerio Grossi;Anna Monreale;Mirco Nanni;Dino Pedreschi;Franco Turini;;;;;;;;;
22;2015;guidotti2015towards;Towards a Boosted Route Planner Using Individual Mobility Models;Route planners generally return routes that minimize either the distance covered or the time traveled. However, these routes are rarely considered by people who move in a certain area systematically. Indeed, due to their expertise, they very often prefer different solutions. In this paper we provide an analytic model to study the deviations of the systematic movements from the paths proposed by a route planner. As proxy of human mobility we use real GPS traces and we analyze a set of users which act in Pisa and Florence province. By using appropriate mobility data mining techniques, we extract the GPS systematic movements and we transform them into sequences of road segments. Finally, we calculate the shortest and fastest path from the origin to the destination of each systematic movement and we compare them with the routes mapped on the road network. Our results show that about 30–35% of the systematic movements follow the shortest paths, while the others follow routes which are on average 7 km longer. In addition, we divided the area object of study in cells and we analyzed the deviations in the flows of systematic movements. We found that, these deviations are not only driven by individual mobility behaviors but are a signal of an existing common sense that could be exploited by a route planner.;Riccardo Guidotti;Paolo Cintia;;;;;;;;;;;;
23;2015;van2015design;Design of a Business-to-Government Information Sharing Architecture Using Business Rules;Information sharing between businesses and government agencies is of vital importance, yet business are often reluctant to share information, e.g. as it might be misused. Taking this into account is however often overlooked in the design of software architectures. In this research we apply a design science approach to develop an software architecture that is acceptable by businesses. From a case study we derive the requirements an architecture should meet in order to contribute to increasing willingness to share information. In this paper the architecture is developed and evaluated according to the requirements. We recommend the use of different types of business rules that provide businesses with control over their data, in combination with encryption and decryption of data to provide access to parts of the data within an organization.;Sélinde van Engelenburg;Marijn Janssen;Bram Klievink;;;;Software-architecture;Information sharing;Business rules;Encryption;Decryption;Supply chain;Customs;
24;2015;cerone2015process;Process Mining as a Modelling Tool: Beyond the Domain of Business Process Management;Process mining emerged in the field of business process management (BPM) as an innovative technique to exploit the large amount of data recorded by information systems in the form of event logs. It allows to discover not only relations and structure in data but also control flow, and produces a process model, which can then be visualised as a process map. In addition to discovery, process mining supports conformance analysis, a technique to compare an a priori model with the event logs to detect deviations and inconsistencies. In this paper we go beyond the domain of BPM and illustrate how process mining and conformance analysis can be used in a number of contexts, in and across the areas of human-computer interaction and learning.;Antonio Cerone;;;;;;;;;;;;;
25;2015;shams2015integrating;On Integrating Social and Sensor Networks for Emergency Management;The 2010 earthquake in Haiti is often referred to as the turning point that changed the way social media can be used during disasters. The development of strategies, technologies and tools to enhance user collaboration around disasters has become an emergent field, and their integration with appropriate sensor networks presents itself as an effective solution to drive decision making in emergency management. In this paper, we present a review of existing disaster management systems and their underlying strategies and technologies, and identify the limitations of the tools in which they are implemented. We then propose an architecture for disaster management that integrates the mining of social networks and the use of sensor networks as two complementary technologies to overcome the limitations of the current emergency management tools.;Farshad Shams;Antonio Cerone;Rocco De Nicola;;;;;;;;;;;
26;2015;galpin2015quantitative;Quantitative Modelling of Residential Smart Grids;Generation of electricity has traditionally taken place at a small number of power stations but with advances in generating technology, small-scale generation of energy from wind and sun is now possible at individual buildings. Additionally, the integration of information technology into the generation and consumption process provides the notion of smart grid. Formal modelling of these systems allows for an understanding of their dynamic behaviour without building or interacting with actual systems. This paper reports on using a quantitative process algebra HYPE to model a residential smart grid (microgrid) for a spatially extensive suburb of houses where energy is generated by wind power at each house and where excess energy can be shared with neighbours and between neighbourhoods. Both demand and wind availability are modelled stochastically, and the goal of the modelling is to understand the behaviour of the system under different redistribution policies that use local knowledge with spatial heterogeneity in wind availability.;Vashti Galpin;;;;;;Smart grid;Microgrid;Renewable energy;Process algebra;Quantitative modelling;Stochastic hybrid;Collective adaptive system;
27;2015;barbuti2015attributed;Attributed Probabilistic P Systems and Their Application to the Modelling of Social Interactions in Primates;We propose a variant of probabilistic P Systems, Attributed Probabilistic P systems (APP systems), in which objects are annotated with attributes. We use APP systems for modelling social behaviours of some species of primates. In this context attributes can represent position of the animals in the environment, age of the animal, dominance level, aggressiveness, etc. As in standard P systems, the dynamics of the system is described by multiset rewrite rules that are applied in a maximally parallel way. Probabilities of rule application, in a maximal step, are computed according to weight functions associated to rules. As an application, we develop models to compare despotic and egalitarian behaviours on different species of primates.;Roberto Barbuti;Alessandro Bompadre;Pasquale Bove;Paolo Milazzo;Giovanni Pardini;;;;;;;;;
28;2015;cini2015probabilistic;Probabilistic Modelling and Analysis of a Fish Population;The fish stock of the common sole in the Adriatic Sea has been analysed by agent-based modelling and simulation techniques as an integration of other classical stock assessment models. In this work we start investigating also about the formal probabilistic modelling of our case study in order to extract valuable biological information from available formal verification techniques. In particular, a PRISM model for the common sole is developed and some initial results are discussed.;Chiara Cini;Luca Tesei;Giuseppe Scarcella;Cesar Augusto Nieto Coria;Emanuela Merelli;;Fish stock assessment;Common sole;Adriatic Sea;Probabilistic models;PRISM model checker;;;
29;2015;setiawan2015tool;A Tool for the Modelling and Simulation of Ecological Systems Based on Grid Systems;Grid Systems is a formalism for modelling population and ecosystem dynamics that combines features of membrane computing, such as rewrite rules and maximal parallelism, with a representation of space similar to that of Cellular Automata. Moreover, Grid Systems include features for the description of environmental events and of events that can be associated with frequencies and durations that can be either deterministic or stochastic. The combination of all of these features makes Grid Systems a comprehensive formalism for the modelling and analysis of ecosystems. This tool paper describes the implementation and the features of a simulator for Grid Systems. The simulator is equipped with a graphical user interface for defining and editing models of populations, and for simulating population dynamics and movement. The aim of this tool is to allow modellers to construct and analyse models based on a comprehensive and rigorous formalism such as Grid Systems with a friendly interface.;Suryana Setiawan;Antonio Cerone;Paolo Milazzo;;;;;;;;;;;
30;2016;atienza2016separating;Separating Topological Noise from Features Using Persistent Entropy;Topology is the branch of mathematics that studies shapes and maps among them. From the algebraic definition of topology a new set of algorithms have been derived. These algorithms are identified with "computational topology" or often pointed out as Topological Data Analysis (TDA) and are used for investigating high-dimensional data in a quantitative manner. Persistent homology appears as a fundamental tool in Topological Data Analysis. It studies the evolution of k-dimensional holes along a sequence of simplicial complexes (i.e. a filtration). The set of intervals representing birth and death times of k-dimensional holes along such sequence is called the persistence barcode. k-dimensional holes with short lifetimes are informally considered to be topological noise, and those with a long lifetime are considered to be topological feature associated to the given data (i.e. the filtration). In this paper, we derive a simple method for separating topological noise from topological features using a novel measure for comparing persistence barcodes called persistent entropy.;Nieves Atienza;Rocio Gonzalez-Diaz;Matteo Rucco;;;;Persistent homology;Persistence barcodes;Shannon entropy;Topological noise;Topological features;;;
31;2016;hajkacem2016accelerated;An Accelerated MapReduce-Based K-prototypes for Big Data;Big data are often characterized by a huge volume and a variety of attributes namely, numerical and categorical. To address this issue, this paper proposes an accelerated MapReduce-based k-prototypes method. The proposed method is based on pruning strategy to accelerate the clustering process by reducing the unnecessary distance computations between cluster centers and data points. Experiments performed on huge synthetic and real data sets show that the proposed method is scalable and improves the efficiency of the existing MapReduce-based k-prototypes method.;Mohamed Aymen Ben HajKacem;Chiheb-Eddine Ben N'cir;Nadia Essoussi;;;;K-prototypes;MapReduce;Big data;Mixed data;;;;
32;2016;cerone2016refinement;Refinement Mining: Using Data to Sift Plausible Models;Process mining techniques have been developed in the ambit of business process management to extract information from event logs consisting of activities and then produce a graphical representation of the process control flow, detect relations between components involved in the process and infer data dependencies between process activities. These process characterisations allow the analyst to discover an annotated visual representation of the conceptual model or the performance model of the process, check conformance with an a priori model to detect deviations and extend the a priori model with quantitative information such as frequencies and performance data. However, a process model yielded by process mining techniques is more similar to a representation of the process behaviour rather than an actual model of the process: it often consists of a huge number of states and interconnections between them, thus resulting in a spaghetti-like net which is hard to interpret or even read. In this paper we propose a novel technique, which we call model mining, to derive an abstract but concise and functionally structured model from event logs. Such a model is not a representation of the unfolded behaviour, but comprises, instead, a set of formal rules for generating the system behaviour. The set of rules is inferred by sifting a plausible a priori model using the event logs as a sieve until a reasonably concise model is achieved (refinement mining). We use rewriting logic as the formal framework in which to perform model mining and implement our framework using the MAUDE rewrite system. Once the final formal model is attained, it can be used, within the same rewriting logic framework, to predict future evolutions of the behaviour through simulation, to carry out further validation or to analyse properties through model checking. We illustrate our approach on a case study from the field of ecology.;Antonio Cerone;;;;;;Formal methods;Model-driven approaches;Process mining;Application to ecosystem modelling;;;;
33;2016;ellison2016towards;Towards Platform Independent Database Modelling in Enterprise Systems;Enterprise software systems are prevalent in many organisations, typically they are data-intensive and manage customer, sales, or other important data.When an enterprise system needs to be modernised or migrated (e.g. to the cloud) it is necessary to understand the structure of this data and how it is used. We have developed a tool-supported approach to model database structure, query patterns, and growth patterns. Compared to existing work, our tool offers increased system support and extensibility which is vital for use in industry. Standardisation and platform independence is ensured by producing models conforming to the Knowledge Discovery Metamodel and Software Metrics Metamodel.;Martyn Ellison;Radu Calinescu;Richard F. Paige;;;;;;;;;;;
34;2016;guidotti2016udio;Audio Ergo Sum A Personal Data Model for Musical Preferences;Nobody can state "Rock is my favorite genre" or "David Bowie is my favorite artist". We defined a Personal Listening Data Model able to capture musical preferences through indicators and patterns, and we discovered that we are all characterized by a limited set of musical preferences, but not by a unique predilection. The empowered capacity of mobile devices and their growing adoption in our everyday life is generating an enormous increment in the production of personal data such as calls, positioning, online purchases and even music listening. Musical listening is a type of data that has started receiving more attention from the scientific community as consequence of the increasing availability of rich and punctual online data sources. Starting from the listening of 30k Last.Fm users, we show how the employment of the Personal Listening Data Models can provide higher levels of self-awareness. In addition, the proposed model will enable the development of a wide range of analysis and musical services both at personal and at collective level.;Riccardo Guidotti;Giulio Rossetti;Dino Pedreschi;;;;;;;;;;;
35;2016;pardini2016high;A High-Level Model Checking Language with Compile-Time Pruning of Local Variables;Among Model Checking tools, the behaviour of a system is often formalized as a transition system with atomic propositions associated with states (Kripke structure). In current modelling languages, transitions are usually specified as updates of the system's variables to be performed when certain conditions are satisfied. However, such a lowlevel representation makes the description of complex transformations difficult, in particular in the presence of structured data. We present a high-level language with imperative semantics for modelling finite-state systems. The language features are selected with the aim of enabling the translation of models into compact transition systems, amenable to efficient verification via Model Checking. To this end, we have developed a compiler of our high-level language into the modelling language of the PRISM probabilistic model checker. One of the main characteristics of the language is that it makes a very different treatment of global and local variables. It is assumed that global variables are actually the variables that describe the state of the modelled system, whereas local variables are only used to ease the specification of the systems internal mechanisms. In this paper we describe the procedure for the pruning of local variables that is executed at compile time.;Giovanni Pardini;Paolo Milazzo;;;;;;;;;;;;
36;2016;reijsbergen2016probabilistic;Probabilistic Modelling of Station Locations in Bicycle-Sharing Systems;We present a simulation methodology for generating the locations of stations in Bicycle-Sharing Systems. We present several methods that are inspired by the literature on spatial point processes. We evaluate how the artificially generated systems compare to existing systems through a case study involving 11 cities worldwide. The method that is found to perform best is a data-driven approach in which we use a dataset of places of interest in the city to 'rate' how attractive city areas are for station placement. The presented methods use only non-proprietary data readily available via the Internet.;Daniël Reijsbergen;;;;;;;;;;;;;
37;2017;andrei2018temporal;Temporal Analytics for Software Usage Models;We address the problem of analysing how users actually interact with software. Users are heterogeneous: they adopt different usage patterns and each individual user may move between different patterns, from one interaction session to another, or even during an interaction session. For analysis, we require new techniques to model and analyse temporal data sets of logged interactions with the purpose of discovering, interpreting, and communicating meaningful patterns of usage. We define new probabilistic models whose parameters are inferred from logged time series data of user-software interactions. We formulate hypotheses about software usage together with the developers, encode them in probabilistic temporal logic, and analyse the models according to the probabilistic properties. We illustrate by application to logged data from a deployed mobile application software used by thousands of users.;Oana Andrei;Muffy Calder;;;;;;;;;;;;
38;2017;andreagiovanni2018sequential;Sequential Pattern Mining for ICT Risk Assessment and Prevention;Security risk assessment and prevention in ICT systems rely on the analysis of data on the joint behavior of the system and its (malicious) users. The Haruspex tool models intelligent, goal-oriented agents that reach their goals through attack sequences. Data is synthetically generated through a Monte Carlo method that runs multiple simulations of the attacks against the system. In this paper, we present a sequential pattern mining analysis of the database of attack sequences. The intended objective is twofold: (1) to exploit the extracted patterns for the design of attack counter-measures, and (2) for gaining a better understanding of the "degree of freedom" available for the attackers of a system. We formally motivate the need for using maximal sequential patterns, instead of frequent or closed sequential patterns, and report on the results on a specific case study.;Michele D'Andreagiovanni;Fabrizio Baiardi;Jacopo Lipilini;Salvatore Ruggieri;Federico Tonelli;;Security risk assessment;Attack sequences;Sequential pattern mining;Maximum coverage problem;;;;
39;2017;backenkohler2018student;Student Performance Prediction and Optimal Course Selection: An MDP Approach;Improving the performance of students is an important challenge for higher education institutions. At most European universities, duration and completion rate of degrees are highly varying and consulting services are offered to increase student achievement. Here, we propose a data analytics approach to determine optimal choices for the courses of the next term. We use machine learning techniques to predict the performance of a student in upcoming courses. These prediction form the transition probabilities of a Markov decision process (MDP) that describes the course of studies of a student. Using this model we plan to explore the effect of different strategies on student performance.;Michael Backenköhler;Verena Wolf;;;;;;;;;;;;
40;2017;broccia2018algorithm;An Algorithm for Simulating Human Selective Attention;The brain mechanism of selective attention plays a key role in determining the success of a human's interaction with a device. If the user has to perform concurrent tasks by interacting simultaneously with more than one device, her/his attention is directed at one of the devices at a time. Attention can therefore be seen as a shared resource, and the attentional mechanisms play the role of a task scheduler. In this paper we propose an algorithm for simulating the human selective attention. Simulations can then be used to study situations in which a user has to interact simultaneously with multiple devices. This kind of study is particularly important in safety-critical contexts in which failures in the main task, such as driving a car or setting an infusion pump, may have serious consequences.;Giovanna Broccia;Paolo Milazzo;Peter Csaba Ölveczky ;;;;Simulation algorithm;Human-computer interaction;Selective attention;Cognitive load;;;;
41;2017;carmichael2018learning;Learning Decision Trees from Synthetic Data Models for Human Security Behaviour;In general, in order to predict the impact of human behaviour on the security of an organisation, one can either build a classifier from actual traces observed within the organisation, or build a formal model, integrating known existing behavioural elements. Whereas the former approach can be costly and time-consuming, and it can be complicated to select the best classifier, it can be equally complicated to select the right parameters for a concrete setting in the latter approach. In this paper, we propose a methodical assessment of decision trees to predict the impact of human behaviour on the security of an organisation, by learning them from different sets of traces generated by a formal probabilistic model we designed. We believe this approach can help a security practitioner understand which features to consider before observing real traces from an organisation, and understand the relationship between the complexity of the behaviour model and the accuracy of the decision tree. In particular, we highlight the impact of the norm and messenger effects, which are well-known influencers, and therefore the crucial importance to capture observations made by the agents. We demonstrate this approach with a case study around tailgating. A key result from this work shows that probabilistic behaviour and influences reduce the effectiveness of decision trees and, importantly, they impact a model differently with regards to error rate, precision and recall.;Peter Carmichael;Charles Morisset;;;;;;;;;;;;
42;2017;griffioen2018controlling;Controlling Production Variances in Complex Business Processes;Products can consist of many sub-assemblies and small disturbances in the process can lead to larger negative effects downstream. Such variances in production are a challenge from a quality control and operational risk management perspective but also it distorts the assurance processes from an auditing perspective. To control production effectively waste needs to be taken into account in normative models, but this is complicated by cumulative effects. We developed an analytical normative model based on the bill of material, that derives the rejection rates from the underlying processes without direct measurement. The model enables improved analysis and prediction. If the rejection rate is not taken into account the function of the bill of material as a reference model deteriorates and therefore output measures become more opaque and harder to verify. As a consequence it is extremely difficult or even impossible to assess efficiency and effectiveness of operations. Secondly it is impossible to judge whether net salable assets represent the correct amount and finally it is impossible to assert whether the operations do comply to company standards and applicable laws.;Paul Griffioen;Rob Christiaanse;Joris Hulstijn;;;;;;;;;;;
43;2017;nasti2018computational;A Computational Model of Internet Addiction Phenomena in Social Networks;Addiction is a complex phenomenon, stemming from environmental, biological and psychological causes. It is defined as a natural response of the body to external stimuli, such as drugs, alcohol, but also job, love and Internet technologies, that become compulsive needs, difficult to remove. At the neurological level, the Dopamine System plays a key role in the addiction process. Mathematical models of the Dopamine System have been proposed to study addiction to nicotine, drugs and gambling. In this paper, we propose a Hybrid Automata model of the Dopamine System, based on the mathematical model proposed by Gutkin et al. Our model allows different kinds of addiction causes to be described. In particular, we consider the problem of Internet addiction and its spread through interaction on social networks. This study is undertaken by performing simulations of virtual social networks by varying the network topology and the interaction propensity of users. We show that scale-free networks favour the emergence of addiction phenomena, in particular when users having a high propensity to interaction are present.;Lucia Nasti;Paolo Milazzo;;;;;Computational model;Hybrid Automata;Simulation;Scale-free networks;Dopamine System;Internet addiction;Social networks;
44;2017;van2017belongs;What Belongs to Context? A Definition, a Criterion and a Method for Deciding on What Context-Aware Systems Should Sense and Adapt to;Context-awareness refers to the ability to sense and adapt to context. With the rise of context-aware systems, designers are struggling with what variables should be sensed from the context. According to the definitions found in the literature, whether something belongs to context, has to do with whether it is relevant. However, what it means to be relevant is left implicit in these definitions. Most work on context-aware systems is based on assumptions of the context that should be taken into account. Hence, it is unclear how to decide whether something belongs to context or should be left out. In this paper, first we analyse what is meant with context and provide a definition. In this definition we introduce the notion of a context variable, defined as an attribute of an object that is relevant. Context is then defined as the set of context variables. We establish explicit criteria for deciding whether an attribute of an object is a context variable based on the proposed definition and the designer's goal. We also provide a straightforward method to help designers to determine whether the criterion is met and a variable should be included in the context. This method is based on filling out a scheme to describe context variables.;Sélinde van Engelenburg;Marijn Janssen;Bram Klievink;;;;Context-aware systems;Context;Business-to-government;Information sharing;Context variable;Context relationship;;
45;2017;zakirzyanov2018finding;Finding All Minimum-Size DFA Consistent with Given Examples: SAT-Based Approach;Deterministic finite automaton (DFA) is a fundamental concept in the theory of computation. The NP-hard DFA identification problem can be efficiently solved by translation to the Boolean satisfiability problem (SAT). Previously we developed a technique to reduce the problem search space by enforcing DFA states to be enumerated in breadth-first search (BFS) order. We proposed symmetry breaking predicates, which can be added to Boolean formulae representing various automata identification problems. In this paper we continue the study of SAT-based approaches. First, we propose new predicates based on depth-first search order. Second, we present three methods to identify all non-isomorphic automata of the minimum size instead of just one - the #P-complete problem which has not been solved before. Third, we revisited our implementation of the BFS-based approach and conducted new evaluation experiments. It occurs that BFS-based approach outperforms all other exact algorithms for DFA identification and can be effectively applied for finding all solutions of the problem.;Ilya Zakirzyanov;Anatoly Shalyto;Vladimir Ulyantsev;;;;Grammatical inference;Automata identification;Symmetry breaking;Boolean satisfiability;;;;
46;2018;nasti2018formalizing;Formalizing a Notion of Concentration Robustness for Biochemical Networks;The main goal of systems biology is to understand the dynamical properties of biological systems by investigating the interactions among the components of a biological system. In this work, we focus on the robustness property, a behaviour observed in several biological systems that allows them to preserve their functions despite external and internal perturbations. We first propose a new formal definition of robustness using the formalism of continuous Petri nets. In particular, we focus on robustness against perturbations to the initial concentrations of species. Then, we demonstrate the validity of our definition by applying it to the models of three different robust biochemical networks.;Lucia Nasti;Roberta Gori;Paolo Milazzo;;;;Robustness;Biochemical networks;Petri nets;;;;;
47;2018;guidotti2018explaining;Explaining Successful Docker Images Using Pattern Mining Analysis;Docker is on the rise in today's enterprise IT. It permits shipping applications inside portable containers, which run from so called Docker images. Docker images are distributed in public registries, which also monitor their popularity. The popularity of an image directly impacts on its usage, and hence on the potential revenues of its developers. In this paper, we present a frequent pattern mining-based approach for understanding how to improve an image to increase its popularity. The results in this work can provide valuable insights to Docker image providers, helping them to design more competitive software products.;Riccardo Guidotti;Jacopo Soldani;Davide Neri;Antonio Brogi;;;;;;;;;;
48;2018;pellungrini2018analyzing;Analyzing Privacy Risk in Human Mobility Data;Mobility data are of fundamental importance for understanding the patterns of human movements, developing analytical services and modeling human dynamics. Unfortunately, mobility data also contain individual sensitive information, making it necessary an accurate privacy risk assessment for the individuals involved. In this paper, we propose a methodology for assessing privacy risk in human mobility data. Given a set of individual and collective mobility features, we define the minimum data format necessary for the computation of each feature and we define a set of possible attacks on these data formats. We perform experiments computing the empirical risk in a real-world mobility dataset, and show how the distributions of the considered mobility features are affected by the removal of individuals with different levels of privacy risk.;Roberto Pellungrini;Luca Pappalardo;Francesca Pratesi;Anna Monreale;;;;;;;;;;
49;2018;arnaboldi2018generating;Generating Synthetic Data for Real World Detection of DoS Attacks in the IoT;Denial of service attacks are especially pertinent to the internet of things as devices have less computing power, memory and security mechanisms to defend against them. The task of mitigating these attacks must therefore be redirected from the device onto a network monitor. Network intrusion detection systems can be used as an effective and efficient technique in internet of things systems to offload computation from the devices and detect denial of service attacks before they can cause harm. However the solution of implementing a network intrusion detection system for internet of things networks is not without challenges due to the variability of these systems and specifically the difficulty in collecting data. We propose a model-hybrid approach to model the scale of the internet of things system and effectively train network intrusion detection systems. Through bespoke datasets generated by the model, the IDS is able to predict a wide spectrum of real-world attacks, and as demonstrated by an experiment construct more predictive datasets at a fraction of the time of other more standard techniques.;Luca Arnaboldi;Charles Morisset;;;;;;;;;;;;
50;2018;bowles2018annotated;Annotated BPMN Models for Optimised Healthcare Resource Planning;There is an unquestionable need to improve healthcare processes across all levels of care in order to optimise the use of resources whilst guaranteeing high quality care to patients. However, healthcare processes are generally very complex and have to be fully understood before enhancement suggestions can be made. Modelling with widely used notation such as BPMN (Business Process Modelling and Notation) can help gain a shared understanding of a process, but is not sufficient to understand the needs and demands of resources. We propose an approach to enrich BPMN models with structured annotations which enables us to attach further information to individual elements within the process model. We then use performance analysis (e.g., throughput and utilisation) to reason about resources across a model and propose optimisations. We show the usefulness of our approach for an A&E department of a sizeable hospital in the south of Brazil and how different stakeholders may profit from a richer annotated BPMN-based model.;Juliana Bowles;Ricardo M. Czekster;Thais Webber;;;;Process modelling;BPMN;Performance analysis;Optimisation;Healthcare;;;
51;2018;cerone2018using;Using Formal Methods to Validate Research Hypotheses: The Duolingo Case Study;In this paper we present a methodology that combines formal methods and informal research methods to validate research hypotheses. We use the CSP (Communicating Sequential Processes) process algebra to model the system as well as some aspects of the user, and PAT (Process Analysis Toolkit) to perform formal verification. We illustrate our methodology on Duolingo, a very popular application for language learning. Two kinds of data are considered: a log of the interaction of the user with the application and the assessment of the user's level of proficiency in the language to be learned (subject profile). The goal is to validate research hypotheses that relate the subject profile to the user's cognitive approach during interaction (cognitive profile). To this purpose, two CSP processes, one modelling the cognitive profile that is associated by the considered research hypothesis to the subject profile and one modelling the interaction log are composed in parallel with the system model. Thus, for each user with the given learner profile and specific interaction log, the verification of the functional correctness of the overall system validates the correlation between cognitive profile and subject profile.;Antonio Cerone;Aiym Zhexenbayeva;;;;;Formal methods;CSP process algebra;Process Analysis Toolkit (PAT);Multimodal interaction;Language learning application;;;
52;2018;cuculo2018personality;Personality Gaze Patterns Unveiled via Automatic Relevance Determination;Understanding human gaze behaviour in social context, as along a face-to-face interaction, remains an open research issue which is strictly related to personality traits. In the effort to bridge the gap between available data and models, typical approaches focus on the analysis of spatial and temporal preferences of gaze deployment over specific regions of the observed face, while adopting classic statistical methods. In this note we propose a different analysis perspective based on novel data-mining techniques and a probabilistic classification method that relies on Gaussian Processes exploiting Automatic Relevance Determination (ARD) kernel. Preliminary results obtained on a publicly available dataset are provided.;Vittorio Cuculo;Alessandro D'Amelio;Raffaella Lanzarotti;Giuseppe Boccignone;;;Eye movement;Gaze;Social interaction;Human behaviour;Gaussian Process;Classification;Personality;Big five
53;2018;cerone2018formalminer;FormalMiner: A Formal Framework for Refinement Mining;Refinement mining has been inspired by process mining techniques and aims to refine an abstract non-deterministic model by sifting it using event logs as a sieve until a reasonably concise model is achieved. FormalMiner is a formal framework that implements model mining using Maude, a modelling language based on rewriting logic. Once the final formal model is attained, it can be used, within the same rewriting-logic framework, to predict the future evolution of the behaviour through simulation, to carry out further validation or to analyse properties through model checking. In this paper we focus on the refinement mining capability of FormalMiner and we illustrate it using a case study from ecology.;Antonio Cerone;;;;;;Formal methods;Model-driven approaches;Rewriting logic;Maude;Process mining;Application to ecosystem modelling;;
54;2019;broccia2020validation;Validation of a Simulation Algorithm for Safety-Critical Human Multitasking;Multitasking has become surprisingly present in our life. This is mostly due to the fact that nowadays most of our activities involve the interaction with one or more devices. In such a context the brain mechanism of selective attention plays a key role in determining the success of a human's interaction with a device. Indeed, it is a resource to be shared among the concurrent tasks to be performed, and the sharing of attention turns out to be a process similar to process scheduling in operating systems. In order to study human multitasking situations in which a user interacts with more than one device at the same time, we proposed in a previous work an algorithm for simulating human selective attention. Our algorithm focuses, in particular, on safety-critical human multitasking, namely situations in which some of the tasks the user is involved in may lead to dangerous consequences if not executed properly. In this paper, we present the validation of such an algorithm against data gathered from an experimental study performed with real users involved concurrently in a "main" task perceived as safety-critical and in a series of "distractor" tasks having different levels of cognitive load.;Giovanna Broccia;Paolo Milazzo;Cristina Belviso;Carmen Berrocal Montiel ;;;Validation;Simulation algorithm;Human-computer interaction;Safety-critical;Multitasking;Experimental study;;
55;2019;garanina2020ontology;An Ontology-Based Approach to Support Formal Verification of Concurrent Systems;Formal verification ensures the absence of design errors in a system with respect to system's requirements. This is especially important for the control software of critical systems, ranging from automatic components of avionics and spacecrafts to modules of distributed banking transactions. In this paper, we present a verification support framework that enables automatic extraction of a concurrent system's requirements from the technical documentation and formal verification of the system design using an external or built-in verification tool that checks whether the system meets the extracted requirements. Our support approach also provides visualization and editing options for both the system model and requirements. The key data components of our framework are ontological descriptions of the verified system and its requirements. We describe the methods used in our support framework and we illustrate their work for the use case of an automatic control system.;Natalia Garanina;Igor Anureev;Elena Sidorova;Dmitry Koznov;Vladimir Zyubin;Sergei Gorlatch;Ontology;Information extraction;Formal verification;Requirement engineering;Formal semantic;;;
56;2019;boccignone2020look;How to Look Next? A Data-Driven Approach for Scanpath Prediction;By and large, current visual attention models mostly rely, when considering static stimuli, on the following procedure. Given an image, a saliency map is computed, which, in turn, might serve the purpose of predicting a sequence of gaze shifts, namely a scanpath instantiating the dynamics of visual attention deployment. The temporal pattern of attention unfolding is thus confined to the scanpath generation stage, whilst salience is conceived as a static map, at best conflating a number of factors (bottom-up information, top-down, spatial biases, etc.). In this note we propose a novel sequential scheme that consists of a three-stage processing relying on a center-bias model, a context/layout model, and an object-based model, respectively. Each stage contributes, at different times, to the sequential sampling of the final scanpath. We compare the method against classic scanpath generation that exploits state-of-the-art static saliency model. Results show that accounting for the structure of the temporal unfolding leads to gaze dynamics close to human gaze behaviour.;Giuseppe Boccignone;Vittorio Cuculo;Alessandro D'Amelio;;;;Saliency model;Visual attention;Gaze deployment;Scanpath prediction;;;;
57;2019;guidotti2020know;Know Thyself How Personal Music Tastes Shape the Last.Fm Online Social Network;As Nietzsche once wrote "Without music, life would be a mistake" (Twilight of the Idols, 1889.). The music we listen to reflects our personality, our way to approach life. In order to enforce self-awareness, we devised a Personal Listening Data Model that allows for capturing individual music preferences and patterns of music consumption. We applied our model to 30k users of Last.Fm for which we collected both friendship ties and multiple listening. Starting from such rich data we performed an analysis whose final aim was twofold: (i) capture, and characterize, the individual dimension of music consumption in order to identify clusters of like-minded Last.Fm users, (ii) analyze if, and how, such clusters relate to the social structure expressed by the users in the service. Do there exist individuals having similar Personal Listening Data Models? If so, are they directly connected in the social graph or belong to the same community?.;Riccardo Guidotti;Giulio Rossetti;;;;;Personal data model;Online social network;Music;;;;;
58;2019;d2020gender;Gender Recognition in the Wild with Small Sample Size - A Dictionary Learning Approach;In this work we address the problem of gender recognition from facial images acquired in the wild. This problem is particularly difficult due to the presence of variations in pose, ethnicity, age and image quality. Moreover, we consider the special case in which only a small sample size is available for the training phase. We rely on a feature representation obtained from the well known VGG-Face Deep Convolutional Neural Network (DCNN) and exploit the effectiveness of a sparse-driven sub-dictionary learning strategy which has proven to be able to represent both local and global characteristics of the train and probe faces. Results on the publicly available LFW dataset are provided in order to demonstrate the effectiveness of the proposed method.;Alessandro D'Amelio;Vittorio Cuculo;Sathya Bursic ;;;;Facial gender recognition;Sparse dictionary learning;Deep features;Soft biometrics;;;;
59;2019;aibassova2020instrumented;An Instrumented Mobile Language Learning Application for the Analysis of Usability and Learning;Mobile applications for language learning (MALL) is a field that is at large dominated by translation-based learning approaches. Moreover, MALL feature a number of common practices that may not effectively address learning or may even increase the number of user errors. In this tool paper, we introduce a language learning application equipped with instrumentation code to collect data about user behavior and use such data in different ways. The most obvious use is to provide statistics and patterns of learning of the users, which can be used by users to adjust their learning approaches and by researchers to study learning processes and attitudes. For the benefit of the user collected data can be also exploited to drive the synthesis of exercises that best suit the user's language level and learning approach and are not likely to cause usability errors. The main use of the application is, however, as a tool for research purposes. In fact, it is a tool for testing new forms of exercises and their combination on samples of users, thus providing valuable information for research in language learning as well as supporting the software development process of new MALL. Finally, an additional feature of the tool is the conversion of the collected data into a formal description of the user's behaviour to be used for formal verification and validation purposes.;Aigerim Aibassova;Antonio Cerone;Mukhtar Tashkenbayev ;;;;Mobile applications;Language learning;Usability;Instrumentation code;;;;
60;2019;natilli2020analysis;Analysis and Visualization of Performance Indicators in University Admission Tests;This paper presents an analytical platform for evaluation of the performance and anomaly detection of tests for admission to public universities in Italy. Each test is personalized for each student and is composed of a series of questions, classified on different domains (e.g. maths, science, logic, etc.). Since each test is unique for composition, it is crucial to guarantee a similar level of difficulty for all the tests in a session. For this reason, to each question, it is assigned a level of difficulty from a domain expert. Thus, the general difficultness of a test depends on the correct classification of each item. We propose two approaches to detect outliers. A visualization-based approach using dynamic filter and responsive visual widgets. A data mining approach to evaluate the performance of the different questions for five years. We used clustering to group the questions according to a set of performance indicators to provide labeling of the data-driven level of difficulty. The measured level is compared with the a priori assigned by experts. The misclassifications are then highlighted to the expert, who will be able to refine the question or the classification. Sequential pattern mining is used to check if biases are present in the composition of the tests and their performance. This analysis is meant to exclude overlaps or direct dependencies among questions. Analyzing co-occurrences we are able to state that the composition of each test is fair and uniform for all the students, even on several sessions. The analytical results are presented to the expert through a visual web application that loads the analytical data and indicators and composes an interactive dashboard. The user may explore the patterns and models extracted by filtering and changing thresholds and analytical parameters.;Michela Natilli;Daniele Fadda;Salvatore Rinzivillo;Dino Pedreschi;Federica Licari;;Performance evaluation;University entrance tests;Cluster analysis;;;;;
61;2019;bursic2020anomaly;Anomaly Detection from Log Files Using Unsupervised Deep Learning;Computer systems have grown in complexity to the point where manual inspection of system behaviour for purposes of malfunction detection have become unfeasible. As these systems output voluminous logs of their activity, machine led analysis of them is a growing need with already several existing solutions. These largely depend on having hand-crafted features, require raw log preprocessing and feature extraction or use supervised learning necessitating having a labeled log dataset not always easily procurable. We propose a two part deep autoencoder model with LSTM units that requires no hand-crafted features, no preprocessing of data as it works on raw text and outputs an anomaly score for each log entry. This anomaly score represents the rarity of a log event both in terms of its content and temporal context. The model was trained and tested on a dataset of HDFS logs containing 2 million raw lines of which half was used for training and half for testing. While this model cannot match the performance of a supervised binary classifier, it could be a useful tool as a coarse filter for manual inspection of log files where a labeled dataset is unavailable.;Sathya Bursic;Vittorio Cuculo;Alessandro D'Amelio ;;;;Deep learning;Anomaly detection;Log file;;;;;
62;2020;finlinson2021synthesis;Synthesis and Pruning as a Dynamic Compression Strategy for Efficient Deep Neural Networks;The brain is a highly reconfigurable machine capable of task-specific adaptations. The brain continually rewires itself for a more optimal configuration to solve problems. We propose a novel strategic synthesis algorithm for feedforward networks that draws directly from the brain's behaviours when learning. The proposed approach analyses the network and ranks weights based on their magnitude. Unlike existing approaches that advocate random selection, we select highly performing nodes as starting points for new edges and exploit the Gaussian distribution over the weights to select corresponding endpoints. The strategy aims only to produce useful connections and result in a smaller residual network structure. The approach is complemented with pruning to further the compression. We demonstrate the techniques to deep feedforward networks. The residual sub-networks that are formed from the synthesis approaches in this work form common sub-networks with similarities up to *90%. Using pruning as a complement to the strategic synthesis approach, we observe improvements in compression.;Alastair Finlinson;Sotiris Moschoyiannis;;;;;Sub-network;Optimisation;Compression;Pruning;Synthesis;;;
63;2020;saueressig2021exploring;Exploring Graph-Based Neural Networks for Automatic Brain Tumor Segmentation;Manual evaluation of medical images, such as MRI scans of brain tumors, requires years of training, is time-consuming, and is often subject to inter-annotator variation. The automatic segmentation of medical images is a long-standing challenge that seeks to alleviate these issues, with great potential benefits for physicians and patients. In the past few years, variations of Convolutional Neural Networks (CNNs) have established themselves as the state-of-the-art methodology for this task. Recently, Graph-based Neural Networks (GNNs) have gained considerable attention in the deep learning community. GNNs exploit the structural information present in graphical data by aggregating information over connected nodes, allowing them to effectively capture relation information between data elements. In this project, we propose a GNN-based approach to brain tumor segmentation. We represent 3D MRI scans of the brain as a graph, where different regions in the images are represented by nodes and edges connect adjacent regions. We apply several variations of GNNs for the automatic segmentation of brain tumors from MRI scans. Our results show GNNs give reasonable performance on the task and allow for realistic modeling of the data. Furthermore, they are far less computationally expensive and time-consuming to train than state-of-the-art segmentation models. Lastly, we assign Shapley value based contribution scores to input MRI features to learn what features are relevant for a particular segmentation, generating interesting insights into explaining the predictions of the proposed model.;Camillo Saueressig;Adam Berkley;Elliot Kang;Reshma Munbodh;Ritambhara Singh;;Graph neural networks;Brain tumor segmentation;Deep learning;;;;;
64;2020;pian2021stdi;STDI-Net: Spatial-Temporal Network with Dynamic Interval Mapping for Bike Sharing Demand Prediction;As an economical and healthy mode of shared transportation, Bike Sharing System (BSS) develops quickly in many big cities. An accurate prediction method can help BSS schedule resources in advance to meet the demands of users, and definitely improve operating efficiencies of it. However, most of the existing methods for similar tasks just utilize spatial or temporal information independently. Though there are some methods consider both, they only focus on demand prediction in a single location or between location pairs. In this paper, we propose a novel deep learning method called Spatial-Temporal Dynamic Interval Network (STDI-Net). The method predicts the number of renting and returning orders of multiple connected stations in the near future by modeling joint spatial-temporal information. Furthermore, we embed an additional module that generates dynamical learnable mappings for different time intervals, to include the factor that different time intervals have a strong influence on demand prediction in BSS. Extensive experiments are conducted on the NYC Bike dataset, the results demonstrate the superiority of our method over existing methods.;Weiguo Pian;Yingbo Wu;Ziyi Kou;;;;Bike sharing system;Demand prediction;Deep learning;;;;;
65;2020;silvina2020simulation;A Simulation-Based Approach for the Behavioural Analysis of Cancer Pathways;Cancer pathway is the name given to a patient's journey from initial suspicion of cancer through to a confirmed diagnosis and, if applicable, the definition of a treatment plan. Typically, a cancer patient will undergo a series of procedures, which we designate as events, during their cancer care. The initial stage of the pathway, from suspected diagnosis to confirmed diagnosis and start of a treatment is called cancer waiting time (CWT). This paper focuses on the modelling and analysis of the CWT. Health boards are under pressure to ensure that the duration of CWT satisfies predefined targets. In this paper, we first create the visual representation of the pathway obtained from real patient data at a given health board, and then compare it with the standardised pathway considered by the board to find and flag a deviation in the execution of the cancer pathway. Next, we devise a discrete event simulation model for the cancer waiting time pathway. The input data is obtained from historical records of patients. The outcomes from this analysis highlight the pathway bottlenecks and transition times which may be used to reveal potential improvements for CWT in the future.;Agastya Silvina;Guilherme Redeker;Thais Webber;Juliana Bowles;;;Cancer pathway;Cancer waiting time;Discrete event simulation;Process modelling;;;;
66;2020;nasti2020discovering;Discovering the Impact of Notifications on Social Network Addiction;Addiction is a complex phenomenon, coming from environmental, biological, and psychological causes. It is defined as a natural response of the body to external stimuli that become compulsive needs. From the biological point of view, the brain has the central role: many neural circuits and, above all, the Dopamine System, are involved in the addiction process. Over the last decade, social network communication has become an increasingly addictive activity, for which users appear to engage in social media excessively and/or compulsively. In this work, we show that the current online social networks' notifications system triggers addictive behaviors. We prove our hypothesis simulating the mathematical modeling of the Dopamine System on real interactions among members of a set of 18 Facebook groups. In line with recent psychological studies, we find that the addicted users show a high frequency of social interactions on the platform.;Lucia Nasti;Andrea Michienzi;Barbara Guidi;;;;Social networks;Computational model;Internet addiction;Facebook groups;;;;
67;2020;bowles2020simulation;A Simulation Study on Demand Disruptions and Limited Resources for Healthcare Provision;Philanthropic hospitals in Brazil are in great part funded by the government and are daily accessed by a large portion of the population. As the Brazilian economy faces deep cuts in healthcare, managers are adjusting budgets and focusing on less expensive alternatives such as process improvements. Hospitals are even more impacted by the recent COVID-19 pandemic with widespread disruption on operational processes forcing them to stretch resources. Thus, it brings an opportunity to evaluate the actual performance of these settings under different scenarios where analysts may address bottlenecks and the impact on resources. Our focus is to quantify the capacity of an emergency department to support patient demand with limited resources in pre and postpandemic scenarios. We use a 12-month longitudinal dataset consisting of pre-pandemic emergency occurrences and assigned resources.;Juliana Bowles;Ricardo M. Czekster;Guilherme Redeker;Thais Webber;;;Healthcare processes;Emergency department;Process simulation;COVID-19;;;;
68;2020;cerone2021formal;A Formal Model for Emulating the Generation of Human Knowledge in Semantic Memory;The transfer of information processed by human beings from their short-term memory (STM) to their semantic memory creates two kinds of knowledge: a semantic network of associations and a structured set of rules to govern human deliberate behaviour under explicit attention. This paper focuses on the memory processes that create the first of these two kinds of knowledge. Human memory storage and processing are modeled using the Real-time Maude rewrite language. Maude's capability of specifying complex data structures as many sorted algebras and the time features of Real-Time Maude are exploited for (1) providing a means for formalising alternative memory models, (2) modelling in silico experiments to compare and validate such models. We aim at using our model for the comparison of alternative cognitive hypothesis and theories and the analysis of interactive systems.;Antonio Cerone;Graham Pluck;;;;;Cognitive science;Human memory models;Formal methods;Rewriting logic;Real-Time Maude;;;
69;2020;milazzo2021analysis;Analysis of COVID-19 Data with PRISM: Parameter Estimation and SIR Modelling;We propose a pipeline for the stochastic analysis of a SIR model for COVID-19 through the stochastic model checker PRISM. The pipeline consists in: (i) the definition of a modified SIR model, able to include governmental restriction and prevention measures through an additional time-dependent coefficient, (ii) parameter estimation based on real epidemic data, (iii) translation of the modified SIR model into a Continuous Time Markov Chain (CTMC) expressed using the PRISM input language, and (iv) stochastic analysis (simulation and model checking) with PRISM.;Paolo Milazzo;;;;;;PRISM model checker;SIR models;COVID-19;;;;;
70;2020;cerone2021formalmodel;A Formal Model for the Simulation and Analysis of Early Biofilm Formation;Biofilms are structured communities of bacterial cells adherent to a surface. This bacterial state is called sessile. This paper focuses on the modelling of the transition between planktonic and sessile state using Real-time Maude as the modelling language. With more and more bacteria joining the sessile community, the likelihood of producing a biofilm increases. Once the percentage of bacterial cells that adheres to the surface reaches a threshold, which is specific for the considered bacterium species, a permanent biofilm is formed. An important challenge is to predict the time needed for the formation of a biofilm on a specific surface, in order to plan when the material infrastructure that comprises such a surface needs to be cleaned or replaced. We exploit the model-checking features of Real-time Maude to formally prove that a regular cleaning or replacement of the infrastructure prevents the biofilm formation.;Antonio Cerone;Enrico Marsili;;;;;Biofilms;Formal methods;Rewriting logic;Real-Time Maude;;;;
71;2020;romero2021query;Query Rewriting on Path Views Without Integrity Constraints;A view with a binding pattern is a parameterised query on a database. Such views are used, e.g., to model Web services. To answer a query on such views, one has to orchestrate the views together in execution plans. The goal is usually to find equivalent rewritings, which deliver precisely the same results as the query on all databases. However, such rewritings are usually possible only in the presence of integrity constraints – and not all databases have such constraints. In this paper, we describe a class of plans that give practical guarantees about their result even if there are no integrity constraints. We provide a characterisation of such plans and a complete and correct algorithm to enumerate them. Finally, we show that our method can find plans on real-world Web Services.;Julien Romero;Nicoleta Preda;Fabian Suchanek;;;;;;;;;;;
72;2020;barbon2020evaluating;Evaluating Trace Encoding Methods in Process Mining;Encoding methods affect the performance of process mining tasks but little work in the literature focused on quantifying their impact. In this paper, we compare 10 different encoding methods from three different families (trace replay and alignment, graph embeddings, and word embeddings) using measures to evaluate the overlaps in the feature space, the accuracy obtained, and the computational resources (time) consumed with a classification task. Across hundreds of event logs representing four variations of five scenarios and five anomalies, it was possible to identify the edge2vec method as the most accurate and effective in reducing class overlapping in the feature space.;Sylvio Barbon Junior;Paolo Ceravolo;Ernesto Damiani;Gabriel Marques Tavares;;;Trace encoding;Word embeddings;Graph embeddings;Classification;Process Mining;;;
73;2020;rahman2021semantic;Semantic Annotations in Clinical Guidelines;Clinical guidelines are evidence-based recommendations developed to assist practitioners in their decisions on appropriate care for patients with specific clinical circumstances. They provide succinct instructions such as what drugs should be given or taken for a particular condition, how long such treatment should be given, what tests should be conducted, or other situational clinical circumstances for certain diseases. However, as they are described in natural language, they are prone to problems such as variability and ambiguity. In this paper, we propose an approach to automatically infer the main components in clinical guideline sentences. Knowing the key concepts in the sentences, we can then feed them to model checkers to validate their correctness. We adapt semantic role labelling approach to mark the key entities in our problem domain. We also implement the technique used for Named-Entity Recognition (NER) task and compare the results. The aim of our work is to build a reasoning framework that combines the information gained from real patient data and clinical practice, with clinical guidelines to give more suitable personalised recommendations for treating patients.;Fahrurrozi Rahman;Juliana Bowles;;;;;Therapy algorithms;Formal verification;Natural language processing;Machine learning;Text tagging;;;
74;2020;munbodh2021deriving;Deriving Performance Measures of Workflow in Radiation Therapy from Real-Time Data;Radiation treatment planning is a complex process with multiple, dependent steps involving an interdisciplinary patient care team. We have previously implemented an interactive, web-based dashboard, which requires a standardised radiation treatment planning workflow and provides real-time monitoring and visualization of the workflow. We present this framework and the results of performance measures characterising the standardised workflow in an effort to optimize clinical efficiency and patient safety. Quantitative representations of longitudinal progression of carepath activities were computed from staff-reported timestamps queried from the EMR. Performance measures evaluated included staff compliance in completing assigned tasks, timeliness in task completion, and the time to complete different tasks. The framework developed allows for informed, data-driven decisions regarding clinical workflow management and the impact of changes on existing workflow as we seek to optimize clinical efficiency and safety, and incorporate new interventions into clinical practice.;Reshma Munbodh;Kara L. Leonard;Eric E. Klein;;;;Workflow tracking;Performance evaluation;Cancer;;;;;
75;2020;abutalipov2021handshape;Handshape Classification in a Reverse Dictionary of Sign Languages for the Deaf;This paper showcases the work that aims at building a user-friendly mobile application of a reverse dictionary to translate sign languages to spoken languages. The concept behind the reverse dictionary is the ability to perform a video-based search by demonstrating a handshape in front of a mobile phone's camera. The user would be able to use this feature in two ways. Firstly, the user would be able to search for a word by showing a handshape for the application to provide a list of signs that contain that handshape. Secondly, the user could fingerspell the word letter by letter in front of the camera for the application to return the sign that corresponds to that word. The user can then look through the suggested videos and see their written translations. To offer other functionalities, the application also has Search by Category and Search by Word options. Currently, the reverse dictionary supports translations from Russian Sign Language (RSL) to Russian language.;Alikhan Abutalipov;Aigerim Janaliyeva;Medet Mukushev;Antonio Cerone;Anara Sandygulova;;Reverse dictionary;Sign language dictionary;Fingerspelling recognition;Video-based search interface;Human-computer interaction;iOS application;Russian Sign Language (RSL);
76;2021;vandin2021multivesta;MultiVeStA: Statistical Analysis of Economic Agent-Based Models by Statistical Model Checking;We overview our recent work on the statistical analysis of simulation models and, especially, economic agent-based models (ABMs). We present a redesign of MultiVeStA, a fully automated and model-agnostic toolkit that can be integrated with existing simulators to inspect simulations and perform counterfactual analysis. Our approach: (i) is easy-to-use by the modeler, (ii) improves reproducibility of results, (iii) optimizes running time given the modeler's machine, (iv) automatically chooses the number of required simulations and simulation steps to reach user-specified statistical confidence, and (v) automatically performs a variety of statistical tests. In particular, our framework is designed to distinguish the transient dynamics of the model from its steady-state behavior (if any), estimate properties of the model in both "phases", and provide indications on the ergodic (or non-ergodic) nature of the simulated processes – which, in turns allows one to gauge the reliability of a steady-state analysis. Estimates are equipped with statistical guarantees, allowing for robust comparisons across computational experiments. This allows us to obtain new insights from models from the literature, and to fix some erroneous conclusions on them.;Andrea Vandin;Daniele Giachini;Francesco Lamperti;Francesca Chiaromonte;;;Agent-based models;Statistical model checking;Ergodicity analysis;Transient analysis;Warmup estimation;T-test and power;;
77;2021;cerone2021ten;Ten Years of DataMod: The Synergy of Data-Driven and Model-Based Approaches;DataMod was founded in 2012 under the acronym of MoKMaSD (Modelling and Knowledge Management for Sustainable Development). The original aim of the Symposium, established by the United Nations University, was to focus on modelling and analysing complex systems while using knowledge management strategies, technology and systems to address problems of sustainable development in various domain areas. The focus was soon expanded to generally addressing the complementarity of model-based and data-driven approaches and the synergetic efforts that can lead to the successful combination of these two approaches. Hence the new name of the Symposium: "From Data to Models and Back" and the new acronym, which have been used since 2016. In this paper we will start from the origins and history of DataMod and will look into the community formed around the Symposium in order to identify some research areas that have been addressed during its first 10 years of life. In this perspective, we will try to understand to which extent the two components of the DataMod community managed to integrate and which synergies between data-driven and model-based approaches have emerged. We will also have a look at what is happening outside DataMod and we will finally discuss which research and collaboration challenges should be addressed by future editions of DataMod.;Antonio Cerone;;;;;;Data-driven approached;Model-based approaches;Formal modelling;Machine learning;Process mining;;;
78;2021;nasti2021analysis;Analysis and Verification of Robustness Properties in Becker-Döring Model;Many biochemical processes in living cells involve clusters of particles. Such processes include protein aggregation and the development of intracellular concentration gradients. To study these mechanisms, we can apply coagulation-fragmentation models describing populations of interacting components. In this context, the Becker-Döring equations - theorized in 1935 - provide the simplest kinetic model to describe condensations phenomena. Experimental works on this model reveal that it exhibits robustness, defined as the system's capability to preserve its features despite noise and fluctuations. Here, we verify the robustness of the BD model, applying our notions of initial concentration robustness (α-robustness and β-robustness), which are related to the influence of the perturbation of the initial concentration of one species (i.e., the input) on the concentration of another species (i.e., the output) at the steady state. Then, we conclude that a new definition of robustness, namely the asymptotic robustness, is necessary to describe more accurately the model's behavior.;Lucia Nasti;Roberta Gori;Paolo Milazzo;;;;Becker-Döring equations;Robustness;Modeling;Simulation;;;;
79;2021;baranov2021secure;A Secure User-Centred Healthcare System: Design and Verification;With ever increasing amounts of travel, it is essential to have access to a patient's medical data from different sources including many jurisdictions. The Serums project addresses this goal by creating a healthcare sharing system that places privacy and security aspects at the center. This raises significant challenges to both maintain privacy and security of medical data and to allow for sharing and access. To address these strict requirements the Serums system design is supported by formal methods where design decisions are modelled and checked to meet safety and security properties. We report an experience in support of the system design with formal modelling with the Uppaal tool and analysis with exhaustive and statistical model checking. Results show that statistical model checking being a simulation-based technique can significantly improve feasibility of analysis while providing support for design decisions to ensure privacy and security.;Eduard Baranov;Juliana Bowles;Thomas Given-Wilson;Axel Legay;Thais Webber;;Healthcare;Data sharing;Privacy;Security;Design verification;Formal modelling;;
80;2021;banton2021model;Model-Based Security Assessment on the Design of a Patient-Centric Data Sharing Platform;The architectural design of a healthcare data sharing system must cope with security requirements especially when the system integrates different data sources and patient-centric features. The design choices come with different risks, where vulnerabilities and threats highly depend on how the system components interact and depend on each other to operate as well as how it handles the external connections. This paper focuses on security aspects arising early in the design phase of a patient-centric system. The system presents a blend of emergent technologies such as novel authentication methods, blockchain for access control, and a data lake for patient metadata storage and retrieval based on access rules. We exploit a model-based approach to tackle security assessment using attack-defense trees (ADtrees) formalism and other support diagrams altogether as a way to model and analyse potential attack paths to the system and its countermeasures. The modelling approach helps creating a framework to support the attack vectors analysis and the proposal of appropriate defense mechanisms within the system architecture.;Matthew Banton;Thais Webber;Agastya Silvina;Juliana Bowles;;;Healthcare systems;Patient-centric system;Data sharing;Security assessment;Attack-defense trees;;;
81;2021;bussi2021towards;Towards Model Checking Video Streams Using VoxLogicA on GPUs;We present a feasibility study on the use of spatial logic model checking for real-time analysis of high-resolution video streams with the tool VoxLogicA. VoxLogicA is a voxel-based image analyser based on the Spatial Logic for Closure Spaces, a logic catered to deal with properties of spatial structures such as topological spaces, graphs and polyhedra. The underlying language includes operators to model proximity and reachability. We demonstrate, via the analysis of a series of video frames from a well-known video game, that it is possible to analyse high-resolution videos in real-time by exploiting the speed-up of VoxLogicA-GPU, a recently developed GPU-based version of the tool, which is 1–2 orders of magnitude faster than its previous iteration. Potential applications of real-time video analysis include medical imaging applications such as ultrasound exams, and other video-based diagnostic techniques. More broadly speaking, this work can be the first step towards novel information retrieval methods suitable to find information in a declarative way, in possibly large collections of video streams.;Laura Bussi;Vincenzo Ciancia;Fabio Gadducci;Diego Latella;Mieke Massink;;;;;;;;;
82;2021;pellungrini2021privacy;Privacy Risk and Data Utility Assessment on Network Data;In the modern Internet era the usage of social networks such as Twitter, Instagram and Facebook is constantly increasing. The analysis of this type of data can help us understand interesting social phenomena, because these networks intrinsically capture the new nature of user interactions. Unfortunately, social network data may reveal personal and sensitive information about users, leading to privacy violations. In this paper, we propose a study of privacy risk for social network data. In particular, we empirically analyze a set of privacy attacks on social network data by using the privacy risk assessment framework PRUDEnce. After simulating the attacks on real data, we first analyze how the privacy risk is distributed over the whole population. Then, we study the effect of high-risk users sanitization on some common network metrics.;Roberto Pellungrini;;;;;;Privacy;Attack models;Social networks;;;;;
83;2021;gray2021detecting;Detecting Anxiety Trends Using Wearable Sensor Data in Real-World Situations;Anxiety can manifest through a range of physiological changes. We develop methods to detect anxiety among medical residents making case presentations in a clinical setting using wearable sensors and machine learning. A number of classifiers are tested on different features extracted from real-time physiological measurements. Our results indicate that anxiety can be detected among healthy volunteers in clinical setting and serve as an introduction to future wearable sensing studies for applications in radiation oncology.;Marissa Gray;Shweta Majumder;Kate Nelson;Reshma Munbodh;;;Wearable sensors;Machine learning;Anxiety detection;Radiation oncology;Heart Rate Variability (HRV);;;
84;2021;piho2021combining;Combining Quantitative Data with Logic-Based Specifications for Parameter Inference;Continuous time Markov chains are a common mathematical model for a range of natural and computer systems. An important part of constructing such models is fitting the model parameters based on some observed data or prior domain knowledge. In this paper we consider the problem of fitting model parameters with respect to a mix of quantitative data and data formulated as temporal logic formulae. Our approach works by defining a set of conditions that capture the dynamics inferred by the quantitative data. This allows for a straightforward way to combine the information from the quantitative and logically specified knowledge into one parameter inference problem via rejection sampling.;Paul Piho;Jane Hillston;;;;;;;;;;;;
85;2021;sochor2021refinement;A Refinement Based Algorithm for Learning Program Input Grammars;We propose and discuss a new algorithm for learning (or equivalently synthesizing) grammars. The algorithm provides good approximations to the set of valid inputs accepted by computer programs. Different to previous works, our algorithm assumes a seed grammar whose language grossly overestimates the target program input language, in the sense that it ideally constitutes a super-set of that. It works by reducing the set of productions from the seed grammar through a heuristically guided process of step-by-step refinement, until a good approximation of the target language is achieved. Evaluation results presented in this paper show that the algorithm can work well in practice, despite the fact that its theoretical complexity is high. We present the algorithm in the context of a use-case and consider possible forms of seed grammar extraction from program abstract syntax trees.;Hannes Sochor;Flavio Ferrarotti;;;;;Program input;Grammar;Learning;Synthesis;Fuzzing;;;
86;2021;li2021spatio;Spatio-temporal Model Checking for 3D Individual-Based Biofilm Simulations;Individual-based microbial modelling (IbM) is a bottom-up approach to study how the heterogeneity of individual microorganisms and their local interactions influence the behaviour of microbial communities. In IbM, microbes are represented as particles endowed with a set of biological and physical attributes. These attributes are affected by both intra- and extra-cellular processes resulting in the emergence of complex spatial and temporal behaviours, such as the morphology of microbial colonies. However, the quantitative and qualitative analysis of such behaviours is difficult and often relies on visual inspection of large quantities of simulation data or on the implementation of sophisticated algorithms for data analysis. In this work, we aim to alleviate the problem by applying SSTL (Signal Spatio-Temporal Logic) model checking to formally analyse the spatial and temporal properties of 3D microbial simulations (so-called traces). Complex behaviours can be then described by simple logical formulas and automatically verified by a model checker. We apply SSTL to analyse several outstanding spatio-temporal behaviours regarding biofilm systems, including biofilm surface dynamics, their detachment and deformation under fluid conditions.;Bowen Li;Jayathilake Pahala Gedara;Yuqing Xia;Thomas P. Curtis;Paolo Zuliani;;Spatio-temporal model checking;Individual-based modelling;SSTL;NUFEB;Biofilm;;;
87;2021;cerone2021web;A Web-Based Tool for Collaborative Modelling and Analysis in Human-Computer Interaction and Cognitive Science;Human-computer interaction and cognitive science are interdisciplinary areas in which computer scientists and mathematicians often work together with social scientists, such as psychologists and sociologists, as well as with more focussed practitioners such as usability experts and system analysts. In order to work effectively, interdisciplinary teams need to agree on a common communication language as a compromise between the computer scientists and mathematicians' formal modelling approach and the conceptual models normally used by social scientists for describing their domain-related theories and frameworks. Moreover, even when proper communication is established within a specific research team, the next challenge is the presentation of the result to a heterogeneous international community, to allow for cross-fertilisation, exchanges of ideas, sharing of models, results and data, work replication and review. This tool paper presents ColMASC, a web-based tool and portal for the collaborative modelling and analysis of human cognition and behaviour as well as interactive systems. ColMASC aim is for researchers in human computer interaction and cognitive science to freely use the tool provided by the web portal in order to collaborate in the development of models of computer/physical systems as well as human behaviour, run in silico experiments, compare the results of in silico experiments and experiments with human beings, perform simulations, analyse systems consisting of computer/physical components and human components, as well as download and upload datasets and models. Domain oriented modelling and visualisation interfaces ease the modelling and analysis processes by hiding the simulation and formal analysis engines.;Antonio Cerone;Anel Mengdigali;Nuray Nabiyeva;Temirlan Nurbay;;;Tool development;Formal methods;Collaborative research;Human-computer interaction;Cognitive science;;;
